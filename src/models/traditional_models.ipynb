{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install rank-bm25 --quiet\n",
        "! pip install vncorenlp --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ff8vX5dPtH_",
        "outputId": "418cf99a-9882-4a3e-f6a6-e679225e1d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p vncorenlp/models/wordsegmenter\n",
        "!mkdir -p vncorenlp/models/postagger\n",
        "!mkdir -p vncorenlp/models/ner\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "!mv VnCoreNLP-1.1.1.jar vncorenlp/\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "!wget -q https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "!mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/postagger/vi-tagger\n",
        "!mv vi-tagger vncorenlp/models/postagger/\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-500brownclusters.xz\n",
        "!wget -q https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-ner.xz\n",
        "!wget -q https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-pretrainedembeddings.xz\n",
        "!mv vi-500brownclusters.xz vncorenlp/models/ner/\n",
        "!mv vi-ner.xz vncorenlp/models/ner/\n",
        "!mv vi-pretrainedembeddings.xz vncorenlp/models/ner/"
      ],
      "metadata": {
        "id": "EDQxn2ttP43Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mm1LLm7_kDe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "import kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_GctxwV01hkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"heeraldedhia/stop-words-in-28-languages\")\n",
        "\n",
        "path_stop_word = path + \"/vietnamese.txt\"\n",
        "path_stop_word = path_stop_word.replace(\"\\\\\", \"/\")\n",
        "with open(path_stop_word, \"r\", encoding=\"utf-8\") as f:\n",
        "    stopwords = f.read().splitlines()\n",
        "\n",
        "stopwords_set = set()\n",
        "for word in stopwords:\n",
        "    stopwords_set.add(word.replace(' ', '_'))"
      ],
      "metadata": {
        "id": "uw_oiXPhClfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "from vncorenlp import VnCoreNLP\n",
        "\n",
        "vncorenlp = VnCoreNLP(\"vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\")\n",
        "\n",
        "def tokennize_vn(text):\n",
        "    sentences = vncorenlp.tokenize(text)\n",
        "    valid_tokens = []\n",
        "    for sentence in sentences:\n",
        "      for token in sentence:\n",
        "        if token not in stopwords_set:\n",
        "          valid_tokens.append(token)\n",
        "\n",
        "    return ' '.join(valid_tokens)"
      ],
      "metadata": {
        "id": "vy3sTXNnKW5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df = pd.read_csv('/content/final_interactions.csv')\n",
        "books_df = pd.read_csv('/content/final_cleaned_books.csv')\n",
        "desc_feat = np.load(\"/content/text_descbook_feat_VisoBert.npy\")\n",
        "typebook_feat = np.load('/content/text_typebook_feat_VisoBert.npy')"
      ],
      "metadata": {
        "id": "M3B6l6Zd_1XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_indexes = books_df.loc[~books_df['description'].isnull(), 'product_index']\n",
        "index_to_product_indexes = {i : index for i, index in enumerate(product_indexes)}\n",
        "description_book = books_df.loc[books_df['product_index'].isin(product_indexes), 'description'].tolist()\n",
        "corpus_tokens = [tokennize_vn(desc).lower().split() for desc in description_book]\n",
        "bm25_corpus = BM25Okapi(corpus_tokens)"
      ],
      "metadata": {
        "id": "Ywl26rk3Ke5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pearson_score(ratingsPivot, id1, id2):\n",
        "    if id1 not in ratingsPivot.index or id2 not in ratingsPivot.index:\n",
        "        return 0.0\n",
        "\n",
        "    vec1 = ratingsPivot.loc[id1]\n",
        "    vec2 = ratingsPivot.loc[id2]\n",
        "    co_mask = vec1.notna() & vec2.notna()\n",
        "\n",
        "    if co_mask.sum() < 2:\n",
        "        return 0.0\n",
        "\n",
        "    a1 = (vec1[co_mask] - vec1[co_mask].mean()).to_numpy()\n",
        "    a2 = (vec2[co_mask] - vec2[co_mask].mean()).to_numpy()\n",
        "    denorminator = np.linalg.norm(a1) * np.linalg.norm(a2)\n",
        "    if denorminator == 0:\n",
        "        return 0.0\n",
        "    return float(np.dot(a1, a2) / denorminator)\n",
        "\n",
        "\n",
        "def cosine_score(ratingsPivot, id1, id2):\n",
        "    vec1 = ratingsPivot.loc[id1]\n",
        "    vec2 = ratingsPivot.loc[id2]\n",
        "    co_mask = vec1.notna() & vec2.notna()\n",
        "\n",
        "    if co_mask.sum() < 2:\n",
        "        return 0.0\n",
        "\n",
        "    a1 = vec1[co_mask].to_numpy()\n",
        "    a2 = vec2[co_mask].to_numpy()\n",
        "    denorminator = np.linalg.norm(a1) * np.linalg.norm(a2)\n",
        "    if denorminator == 0:\n",
        "        return 0.0\n",
        "    return float(np.dot(a1, a2) / denorminator)\n",
        "\n",
        "\n",
        "def pearson_similarity_vector(v1, v2_matrix):\n",
        "    v1 = v1.flatten()\n",
        "    v1_mean = np.mean(v1)\n",
        "    v1_centered = v1 - v1_mean\n",
        "    v1_norm = np.linalg.norm(v1_centered)\n",
        "\n",
        "    v2_means = np.mean(v2_matrix, axis=1, keepdims=True)\n",
        "    v2_centered = v2_matrix - v2_means\n",
        "    v2_norms = np.linalg.norm(v2_centered, axis=1)\n",
        "\n",
        "    denominators = v1_norm * v2_norms\n",
        "    denominators[denominators == 0] = 1e-9\n",
        "\n",
        "    correlation = np.dot(v2_centered, v1_centered) / denominators\n",
        "    return correlation\n",
        "\n",
        "\n",
        "def get_topK_neighbors(ratingsPivot, target_id, k, similarity_name):\n",
        "    if similarity_name == 'Pearson':\n",
        "        similarity_score = [(id, pearson_score(ratingsPivot, target_id, id)) for id in ratingsPivot.index if id != target_id]\n",
        "    elif similarity_name == 'Cosine':\n",
        "        similarity_score = [(id, cosine_score(ratingsPivot, target_id, id)) for id in ratingsPivot.index if id != target_id]\n",
        "    else:\n",
        "        raise ValueError(\"similarity_name must be in ['Pearson', 'Cosine]\")\n",
        "\n",
        "    similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)[:k]\n",
        "    return similarity_score\n",
        "\n",
        "def average_precision_at_k(predictions, true_interactions, k):\n",
        "    if k <= 0 or len(true_interactions) == 0 or len(predictions) == 0:\n",
        "        return 0.0\n",
        "    k_eff = min(k, len(predictions))\n",
        "    ap_k, relevant = 0.0, 0\n",
        "    for i in range(k_eff):\n",
        "        if predictions[i][0] in true_interactions:\n",
        "            relevant += 1\n",
        "            ap_k += relevant / (i + 1)\n",
        "    # common choice: divide by min(k, |relevant set|)\n",
        "    return ap_k / min(k, len(true_interactions))\n",
        "\n",
        "def normal_discounted_cumulative_gain_at_k(predictions, true_interactions, k):\n",
        "    if k <= 0 or len(true_interactions) == 0 or len(predictions) == 0:\n",
        "        return 0.0\n",
        "    k_eff = min(k, len(predictions))\n",
        "    dcg = 0.0\n",
        "    for i in range(k_eff):\n",
        "        if predictions[i][0] in true_interactions:\n",
        "            dcg += 1 / np.log2(i + 2)\n",
        "    idcg = sum(1 / np.log2(i + 2) for i in range(min(k, len(true_interactions))))\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "\n",
        "def precision_at_k(predictions, true_interactions, k):\n",
        "    if k <= 0 or len(predictions) == 0:\n",
        "        return 0.0\n",
        "    k_eff = min(k, len(predictions))\n",
        "    top_k = [pred[0] for pred in predictions[:k_eff]]\n",
        "    return sum(item in true_interactions for item in top_k) / k\n",
        "\n",
        "def recall_at_k(predictions, true_interactions, k):\n",
        "    if len(true_interactions) == 0 or len(predictions) == 0:\n",
        "        return 0.0\n",
        "    k_eff = min(k, len(predictions))\n",
        "    top_k = [pred[0] for pred in predictions[:k_eff]]\n",
        "    return sum(item in true_interactions for item in top_k) / len(true_interactions)\n",
        "\n",
        "\n",
        "def get_recommendation_cf(ratingsPivot, user_id, k_neighbors, similarity_name):\n",
        "    topK_neighbors = get_topK_neighbors(ratingsPivot, user_id, k_neighbors, similarity_name)\n",
        "\n",
        "    total, den = {}, {}\n",
        "    mean_target = ratingsPivot.loc[user_id].mean(skipna=True)\n",
        "\n",
        "    for neighbor_id, score in topK_neighbors:\n",
        "        if neighbor_id not in ratingsPivot.index:\n",
        "            continue\n",
        "\n",
        "        neighbor_ratings = ratingsPivot.loc[neighbor_id]\n",
        "        mean_neighbor = neighbor_ratings.mean(skipna=True)\n",
        "\n",
        "        # Các item neighbor đã rating\n",
        "        items = ratingsPivot.loc[neighbor_id][ratingsPivot.loc[neighbor_id].notna()].index.tolist()\n",
        "        # Các item mà target_id chưa rating\n",
        "        unseen_items = [it for it in items if pd.isna(ratingsPivot.loc[user_id, it])]\n",
        "        if not unseen_items:\n",
        "            continue\n",
        "\n",
        "        for item in unseen_items:\n",
        "            total[item] = total.get(item, 0.0) + score * (neighbor_ratings[item] - mean_neighbor)\n",
        "            den[item]   = den.get(item, 0.0)   + abs(score)\n",
        "\n",
        "    ranking = []\n",
        "    for item, num in total.items():\n",
        "        if den[item] != 0:\n",
        "            pred_rating = mean_target + (num / den[item])\n",
        "            ranking.append((item, float(pred_rating)))\n",
        "\n",
        "    ranking.sort(key=lambda x: x[1], reverse=True)\n",
        "    return ranking\n",
        "\n",
        "\n",
        "def get_recommendation_cb(train_ratingsDF, desc_feat, user_id, similarity_name):\n",
        "    user_data = train_ratingsDF[train_ratingsDF['customer_index'] == user_id]\n",
        "    interacted_idx = user_data['product_index'].tolist()\n",
        "    user_ratings = user_data['rating'].values.reshape(-1, 1)\n",
        "    interacted_vecs = desc_feat[interacted_idx]\n",
        "\n",
        "    user_profile_vec = np.sum(interacted_vecs * user_ratings, axis=0) / np.sum(user_ratings)\n",
        "    user_profile_vec = user_profile_vec.reshape(1, -1)\n",
        "\n",
        "    candidate_indices = [product_index for product_index in train_ratingsDF['product_index'].unique() if product_index not in interacted_idx]\n",
        "    candidate_vecs = desc_feat[candidate_indices]\n",
        "\n",
        "    if similarity_name == 'Cosine':\n",
        "        sim_scores = cosine_similarity(user_profile_vec, candidate_vecs).flatten()\n",
        "    elif similarity_name == 'Pearson':\n",
        "        sim_scores = pearson_similarity_vector(user_profile_vec, candidate_vecs).flatten()\n",
        "    else:\n",
        "        raise ValueError(\"Similarity Name must be in ['Cosine', 'Pearson']\")\n",
        "\n",
        "    recommendations = sorted(zip(candidate_indices, sim_scores), key=lambda x: x[1], reverse=True)\n",
        "    return recommendations\n",
        "\n",
        "def get_recommendation_cb_bm25(train_ratingsDF, user_id, bm25_corpus):\n",
        "    user_data = train_ratingsDF[train_ratingsDF['customer_index'] == user_id]\n",
        "    interacted_idx = user_data['product_index'].tolist()\n",
        "    description_data = books_df.loc[books_df['product_index'].isin(interacted_idx) & ~books_df['description'].isnull(), 'description'].tolist()\n",
        "    if not description_data:\n",
        "        return []\n",
        "\n",
        "    total_scores = defaultdict(float)\n",
        "\n",
        "    for desc in description_data:\n",
        "        tokens = tokennize_vn(str(desc)).lower().split()\n",
        "        scores = bm25_corpus.get_scores(tokens)\n",
        "        for idx, score in enumerate(scores):\n",
        "            total_scores[idx] += score\n",
        "\n",
        "    recommendations = []\n",
        "    check_item = []\n",
        "    for idx, score in total_scores.items():\n",
        "        real_product_id = index_to_product_indexes.get(idx)\n",
        "\n",
        "        # Chỉ thêm vào nếu sách này chưa từng đọc\n",
        "        if real_product_id and (real_product_id not in interacted_idx) and (real_product_id not in check_item):\n",
        "            check_item.append(real_product_id)\n",
        "            recommendations.append((real_product_id, score))\n",
        "\n",
        "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
        "    return recommendations\n",
        "\n",
        "def get_recommendation_test(train_ratingsDF, test_ratingsDF, K, type_rec, similarity_name=None, text_feat=None, typebook_feat=None, bm25_corpus=None):\n",
        "    preds = []\n",
        "    user_ids = test_ratingsDF['customer_index'].tolist()\n",
        "    ap_list, ndcg_list, precision_list, recall_list = [], [], [], []\n",
        "    train_ratingsPivot = train_ratingsDF.pivot(index='customer_index', columns='product_index', values='rating')\n",
        "\n",
        "    for i in tqdm(range(len(user_ids)), desc='Recommend items for User'):\n",
        "        if type_rec == 'cf':\n",
        "          rec_items = get_recommendation_cf(\n",
        "              train_ratingsPivot,\n",
        "              user_id=user_ids[i],\n",
        "              k_neighbors=10,\n",
        "              similarity_name=similarity_name\n",
        "          )\n",
        "        elif type_rec == 'cb':\n",
        "          rec_items = get_recommendation_cb(\n",
        "              train_ratingsDF,\n",
        "              text_feat,\n",
        "              user_id=user_ids[i],\n",
        "              similarity_name=similarity_name\n",
        "          )\n",
        "        elif type_rec == 'typebook_based':\n",
        "          rec_items = get_recommendation_cb(\n",
        "              train_ratingsDF,\n",
        "              typebook_feat,\n",
        "              user_id=user_ids[i],\n",
        "              similarity_name=similarity_name\n",
        "          )\n",
        "        elif type_rec == 'cb_bm25':\n",
        "          rec_items = get_recommendation_cb_bm25(\n",
        "              train_ratingsDF,\n",
        "              user_id=user_ids[i],\n",
        "              bm25_corpus=bm25_corpus\n",
        "          )\n",
        "        else:\n",
        "          raise ValueError(f\"Type Recommendation system must be in ['cf', 'cb', 'cb_bm25', 'typebook_based']\")\n",
        "\n",
        "        preds.append(rec_items)\n",
        "        true_interactions = test_ratingsDF[test_ratingsDF['customer_index'] == user_ids[i]]['product_index'].tolist()\n",
        "\n",
        "        # Tính các metrics cho mỗi dự đoán\n",
        "        ap_list.append(average_precision_at_k(rec_items, true_interactions, K))\n",
        "        ndcg_list.append(normal_discounted_cumulative_gain_at_k(rec_items, true_interactions, K))\n",
        "        precision_list.append(precision_at_k(rec_items, true_interactions, K))\n",
        "        recall_list.append(recall_at_k(rec_items, true_interactions, K))\n",
        "\n",
        "    # Tính giá trị trung bình của tất cả các metrics\n",
        "    mean_ap = sum(ap_list) / len(ap_list)\n",
        "    mean_ndcg = sum(ndcg_list) / len(ndcg_list)\n",
        "    mean_precision = sum(precision_list) / len(precision_list)\n",
        "    mean_recall = sum(recall_list) / len(recall_list)\n",
        "\n",
        "    print(f\"MAP@{K}: {mean_ap}\")\n",
        "    print(f\"NDCG@{K}: {mean_ndcg}\")\n",
        "    print(f\"Precision@{K}: {mean_precision}\")\n",
        "    print(f\"Recall@{K}: {mean_recall}\")\n",
        "\n",
        "    return preds"
      ],
      "metadata": {
        "id": "7f-oxgWNGPJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_parts, test_parts = [], []\n",
        "for user_id, group in reviews_df.groupby('customer_index'):\n",
        "    train_parts.append(group.iloc[:-1])\n",
        "    test_parts.append(group.iloc[[-1]])\n",
        "\n",
        "train_reviews_df = pd.concat(train_parts).reset_index(drop=True)\n",
        "test_reviews_df = pd.concat(test_parts).reset_index(drop=True)\n",
        "\n",
        "print(f\"Training Size: {train_reviews_df.shape}, Testing Size: {test_reviews_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDuQcUDWFuTB",
        "outputId": "5db09f63-c1b7-474c-d93b-40642b109016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Size: (4655, 6), Testing Size: (707, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for K in [5, 10]:\n",
        "    preds = get_recommendation_test(train_reviews_df, test_reviews_df, K, type_rec='cf', similarity_name='Pearson')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC_R7irZO6o_",
        "outputId": "c36d04c0-f6ef-4cd2-8666-a160cb3e9b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [02:07<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@5: 0.000825082508250825\n",
            "NDCG@5: 0.0013163741981236112\n",
            "Precision@5: 0.0005657708628005659\n",
            "Recall@5: 0.002828854314002829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [02:04<00:00,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@10: 0.0010608203677510608\n",
            "NDCG@10: 0.001820203317088282\n",
            "Precision@10: 0.00042432814710042436\n",
            "Recall@10: 0.004243281471004243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for K in [5, 10]:\n",
        "    preds = get_recommendation_test(train_reviews_df, test_reviews_df, K, type_rec='cf', similarity_name='Cosine')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWHhn6qrOY47",
        "outputId": "57505397-dd5f-489c-ef5f-b539de84536a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [02:02<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@5: 0.0027109853842527108\n",
            "NDCG@5: 0.0034380149336257324\n",
            "Precision@5: 0.0011315417256011317\n",
            "Recall@5: 0.005657708628005658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [02:01<00:00,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@10: 0.003926719202532498\n",
            "NDCG@10: 0.0065323073706363075\n",
            "Precision@10: 0.001555869872701556\n",
            "Recall@10: 0.015558698727015558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for K in [5, 10]:\n",
        "    preds = get_recommendation_test(train_reviews_df, test_reviews_df, K, type_rec='cb', similarity_name='Pearson', text_feat=desc_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_pJBPgCFMeG",
        "outputId": "95beb8ec-fab2-4b28-f4c1-d83692bb6420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [00:05<00:00, 123.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@5: 0.002593116454502593\n",
            "NDCG@5: 0.003384426111335746\n",
            "Precision@5: 0.0011315417256011317\n",
            "Recall@5: 0.005657708628005658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [00:06<00:00, 108.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@10: 0.004052446060932624\n",
            "NDCG@10: 0.006996109306402555\n",
            "Precision@10: 0.0016973125884016975\n",
            "Recall@10: 0.016973125884016973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for K in [5, 10]:\n",
        "    preds = get_recommendation_test(train_reviews_df, test_reviews_df, K, type_rec='cb', similarity_name='Cosine', text_feat=desc_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5los7k0Jh5i",
        "outputId": "2d4adffc-a19e-4c5b-aa53-08533ee77f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [00:06<00:00, 112.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@5: 0.002593116454502593\n",
            "NDCG@5: 0.003384426111335746\n",
            "Precision@5: 0.0011315417256011317\n",
            "Recall@5: 0.005657708628005658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [00:07<00:00, 94.85it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@10: 0.004052446060932624\n",
            "NDCG@10: 0.006996109306402555\n",
            "Precision@10: 0.0016973125884016975\n",
            "Recall@10: 0.016973125884016973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for K in [5, 10]:\n",
        "    preds = get_recommendation_test(train_reviews_df, test_reviews_df, K, type_rec='typebook_based', similarity_name='Cosine', typebook_feat=typebook_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3rjI5gsF81N",
        "outputId": "e805aa9a-cb53-47fb-dce0-dde2c50b5538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [00:07<00:00, 100.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@5: 0.005233380480905233\n",
            "NDCG@5: 0.007423204983566234\n",
            "Precision@5: 0.002828854314002829\n",
            "Recall@5: 0.014144271570014143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [00:09<00:00, 78.43it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@10: 0.005812622078534384\n",
            "NDCG@10: 0.008807370962009294\n",
            "Precision@10: 0.0018387553041018388\n",
            "Recall@10: 0.018387553041018388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for K in [5, 10]:\n",
        "    preds = get_recommendation_test(train_reviews_df, test_reviews_df, K, type_rec='typebook_based', similarity_name='Pearson', typebook_feat=typebook_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDttrwpGK-TU",
        "outputId": "d12ac4d3-7bfb-4282-f7f3-a2e35a152464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [00:05<00:00, 131.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@5: 0.002168788307402169\n",
            "NDCG@5: 0.003990264276389321\n",
            "Precision@5: 0.0019801980198019802\n",
            "Recall@5: 0.009900990099009901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [00:03<00:00, 180.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@10: 0.0027048112974562763\n",
            "NDCG@10: 0.0053337270851347846\n",
            "Precision@10: 0.0014144271570014145\n",
            "Recall@10: 0.014144271570014143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for K in [5, 10]:\n",
        "    preds = get_recommendation_test(train_reviews_df, test_reviews_df, K, type_rec='cb_bm25', bm25_corpus=bm25_corpus)"
      ],
      "metadata": {
        "id": "haWhTju3MFG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a4954f-e1cf-414b-d182-5fb47301f523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [03:31<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@5: 0.02524752475247525\n",
            "NDCG@5: 0.029877282528691894\n",
            "Precision@5: 0.00876944837340877\n",
            "Recall@5: 0.04384724186704385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Recommend items for User: 100%|██████████| 707/707 [03:28<00:00,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@10: 0.027747468624413463\n",
            "NDCG@10: 0.03613841938688594\n",
            "Precision@10: 0.006364922206506365\n",
            "Recall@10: 0.06364922206506365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VmgYRa0XQ_Fn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}